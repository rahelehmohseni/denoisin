{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlRBMSJMfQsTaNBvh2EGCS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahelehmohseni/denoising/blob/main/U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0giiAO_iO_vj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile\n",
        "import IPython\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating folder for all clean speech\n",
        "!mkdir clean_sound"
      ],
      "metadata": {
        "id": "yzf6XS11PBKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir noise_sound"
      ],
      "metadata": {
        "id": "rqPwO_PAPDHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_audio_frame_stack(sound_data, frame_length, hop_length_frame):\n",
        "    \"\"\"This function take an audio and split into several frame\n",
        "       in a numpy matrix of size (nb_frame,frame_length)\"\"\"\n",
        "\n",
        "    sequence_sample_length = sound_data.shape[0]\n",
        "    # Creating several audio frames using sliding windows\n",
        "    sound_data_list = [sound_data[start:start + frame_length] for start in range(\n",
        "    0, sequence_sample_length - frame_length + 1, hop_length_frame)]  # get sliding windows\n",
        "    # Combining all the frames to single matrix\n",
        "    sound_data_array = np.vstack(sound_data_list)\n",
        "    return sound_data_array"
      ],
      "metadata": {
        "id": "twDcEv8cPIui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required variables for Audio\n",
        "noise_dir = '/content/noise_sound'\n",
        "voice_dir = '/content/clean_sound'\n",
        "path_save_spectrogram = '/content/spectogram/'\n",
        "sample_rate = 16000\n",
        "min_duration = 1.0\n",
        "frame_length = 8064\n",
        "hop_length_frame = 8064\n",
        "hop_length_frame_noise = 5000\n",
        "nb_samples = 500\n",
        "n_fft = 255\n",
        "hop_length_fft = 63\n",
        "dim_square_spec = int(n_fft / 2) + 1"
      ],
      "metadata": {
        "id": "VLTGuiW7PO3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean Audio files\n",
        "clean_audio_files = os.listdir(voice_dir)\n",
        "# Selecting a random audio from clean speech\n",
        "clean_random_audio = np.random.choice(clean_audio_files)\n",
        "# Load Audio\n",
        "y,sr = librosa.load('/content/clean_sound/1-1750.wav',sr=sample_rate)\n",
        "# Converting to Audio to numpy matrix\n",
        "clean = audio_to_audio_frame_stack(y,frame_length,hop_length_frame)\n",
        "print(\"Clean Audio: {}\".format(clean_random_audio))\n",
        "print(\"Shape:{}\".format(clean.shape))"
      ],
      "metadata": {
        "id": "4IKonMzSPPxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Noisy Audio files\n",
        "noisy_audio_files = os.listdir(noise_dir)\n",
        "# Selecting a random audio from noise data\n",
        "noisy_random_audio = np.random.choice(noisy_audio_files)\n",
        "# Load Audio\n",
        "y,sr = librosa.load('/content/noise_sound/5-1750.wav',sr=sample_rate)\n",
        "# Converting the Audio to numpy matrix\n",
        "noise = audio_to_audio_frame_stack(y,frame_length,hop_length_frame)\n",
        "print(\"Noise Audio: {}\".format(noisy_random_audio))\n",
        "print(\"Shape:{}\".format(noise.shape))"
      ],
      "metadata": {
        "id": "1fjZG8J9PUNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean = np.vstack(clean)\n",
        "noise = np.vstack(noise)"
      ],
      "metadata": {
        "id": "jgQbe6YaPYIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blend_noise_randomly(voice, noise, nb_samples, frame_length):\n",
        "    \"\"\"This function takes as input numpy arrays representing frames\n",
        "    of voice sounds, noise sounds and the number of frames to be created\n",
        "    and return numpy arrays with voice randomly blend with noise\"\"\"\n",
        "\n",
        "    prod_voice = np.zeros((nb_samples, frame_length))\n",
        "    prod_noise = np.zeros((nb_samples, frame_length))\n",
        "    prod_noisy_voice = np.zeros((nb_samples, frame_length))\n",
        "\n",
        "    for i in range(nb_samples):\n",
        "        id_voice = np.random.randint(0, voice.shape[0])\n",
        "        id_noise = np.random.randint(0, noise.shape[0])\n",
        "        level_noise = np.random.uniform(0.2, 0.8)\n",
        "        prod_voice[i, :] = voice[id_voice, :]\n",
        "        prod_noise[i, :] = level_noise * noise[id_noise, :]\n",
        "        prod_noisy_voice[i, :] = prod_voice[i, :] + prod_noise[i, :]\n",
        "\n",
        "    return prod_voice, prod_noise, prod_noisy_voice"
      ],
      "metadata": {
        "id": "ghQgqn9xPav3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prod_voice, prod_noise,prod_noisy_voice = blend_noise_randomly(voice=clean,noise=noise,nb_samples=10,frame_length=frame_length)"
      ],
      "metadata": {
        "id": "jbkxsvk-PeEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_clean = []\n",
        "samples_noisy_clean = []\n",
        "for x in prod_voice:\n",
        "  samples_clean.extend(x)\n",
        "\n",
        "for x in prod_noisy_voice:\n",
        "  samples_noisy_clean.extend(x)"
      ],
      "metadata": {
        "id": "AuL6MB6qPip2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After combining all samples to 1 (10*8064)\n",
        "len(samples_clean)"
      ],
      "metadata": {
        "id": "m8yueKXsPjqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_magnitude_db_and_phase(n_fft, hop_length_fft, audio):\n",
        "    \"\"\"This function takes an audio and convert into spectrogram,\n",
        "       it returns the magnitude in dB and the phase\"\"\"\n",
        "\n",
        "\n",
        "    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n",
        "    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n",
        "\n",
        "    stftaudio_magnitude_db = librosa.amplitude_to_db(\n",
        "        stftaudio_magnitude, ref=np.max)\n",
        "\n",
        "    return stftaudio_magnitude_db, stftaudio_phase"
      ],
      "metadata": {
        "id": "ff74CmJMPqtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def numpy_audio_to_matrix_spectrogram(numpy_audio, dim_square_spec, n_fft, hop_length_fft):\n",
        "    \"\"\"This function takes as input a numpy audi of size (nb_frame,frame_length), and return\n",
        "    a numpy containing the matrix spectrogram for amplitude in dB and phase. It will have the size\n",
        "    (nb_frame,dim_square_spec,dim_square_spec)\"\"\"\n",
        "\n",
        "    # we extract the magnitude vectors from the 256-point STFT vectors and\n",
        "    # take the first 129-point by removing the symmetric half.\n",
        "\n",
        "    nb_audio = numpy_audio.shape[0]\n",
        "    # dim_square_spec = 256/2\n",
        "    m_mag_db = np.zeros((nb_audio, dim_square_spec, dim_square_spec))\n",
        "    m_phase = np.zeros((nb_audio, dim_square_spec, dim_square_spec), dtype=complex)\n",
        "\n",
        "    for i in range(nb_audio):\n",
        "        m_mag_db[i, :, :], m_phase[i, :, :] = audio_to_magnitude_db_and_phase(\n",
        "            n_fft, hop_length_fft, numpy_audio[i])\n",
        "\n",
        "    return m_mag_db, m_phase"
      ],
      "metadata": {
        "id": "Log0H2-wPtob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_files_to_numpy(audio_dir, list_audio_files, sample_rate, frame_length, hop_length_frame, min_duration):\n",
        "    \"\"\"This function take audio files of a directory and merge them\n",
        "    in a numpy matrix of size (nb_frame,frame_length) for a sliding window of size hop_length_frame\"\"\"\n",
        "\n",
        "    list_sound_array = []\n",
        "\n",
        "    count = 0\n",
        "    for file in list_audio_files:\n",
        "    # open the audio file\n",
        "      try:\n",
        "        y, sr = librosa.load(os.path.join(audio_dir, file), sr=sample_rate)\n",
        "        # Getting duration of audio file\n",
        "        total_duration = librosa.get_duration(y=y, sr=sr)\n",
        "      except ZeroDivisionError:\n",
        "        count += 1\n",
        "\n",
        "        # Check if the duration is atleast the minimum duration\n",
        "      if (total_duration >= min_duration):\n",
        "          list_sound_array.append(audio_to_audio_frame_stack(\n",
        "              y, frame_length, hop_length_frame))\n",
        "      else:\n",
        "          print(\n",
        "              f\"The following file {os.path.join(audio_dir,file)} is below the min duration\")\n",
        "\n",
        "    return np.vstack(list_sound_array)"
      ],
      "metadata": {
        "id": "8i0iTFhOPyIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Prepare\n",
        "def create_data(noise_dir, voice_dir,path_save_spectrogram, sample_rate,\n",
        "min_duration, frame_length, hop_length_frame, hop_length_frame_noise, nb_samples, n_fft, hop_length_fft):\n",
        "    \"\"\"This function will randomly blend some clean voices from voice_dir with some noises from noise_dir\n",
        "    and save the spectrograms of noisy voice, noise and clean voices to disk as well as complex phase,\n",
        "    time series and sounds. This aims at preparing datasets for denoising training. It takes as inputs\n",
        "    parameters defined in args module\"\"\"\n",
        "\n",
        "    list_noise_files = os.listdir(noise_dir)\n",
        "    list_voice_files = os.listdir(voice_dir)\n",
        "\n",
        "    def remove_ds_store(lst):\n",
        "        \"\"\"remove mac specific file if present\"\"\"\n",
        "        if '.DS_Store' in lst:\n",
        "            lst.remove('.DS_Store')\n",
        "\n",
        "        return lst\n",
        "\n",
        "    list_noise_files = remove_ds_store(list_noise_files)\n",
        "    list_voice_files = remove_ds_store(list_voice_files)\n",
        "\n",
        "    nb_voice_files = len(list_voice_files)\n",
        "    nb_noise_files = len(list_noise_files)\n",
        "\n",
        "\n",
        "    # Extracting noise and voice from folder and convert to numpy\n",
        "    noise = audio_files_to_numpy(noise_dir, list_noise_files, sample_rate,\n",
        "                                     frame_length, hop_length_frame_noise, min_duration)\n",
        "\n",
        "    voice = audio_files_to_numpy(voice_dir, list_voice_files,\n",
        "                                     sample_rate, frame_length, hop_length_frame, min_duration)\n",
        "\n",
        "    # Blend some clean voices with random selected noises (and a random level of noise)\n",
        "    prod_voice, prod_noise, prod_noisy_voice = blend_noise_randomly(\n",
        "            voice, noise, nb_samples, frame_length)\n",
        "\n",
        "\n",
        "    # Squared spectrogram dimensions\n",
        "    dim_square_spec = int(n_fft / 2) + 1\n",
        "\n",
        "    # Create Amplitude and phase of the sounds\n",
        "    m_amp_db_voice,  m_pha_voice = numpy_audio_to_matrix_spectrogram(\n",
        "            prod_voice, dim_square_spec, n_fft, hop_length_fft)\n",
        "    m_amp_db_noise,  m_pha_noise = numpy_audio_to_matrix_spectrogram(\n",
        "            prod_noise, dim_square_spec, n_fft, hop_length_fft)\n",
        "    m_amp_db_noisy_voice,  m_pha_noisy_voice = numpy_audio_to_matrix_spectrogram(\n",
        "            prod_noisy_voice, dim_square_spec, n_fft, hop_length_fft)\n",
        "\n",
        "    np.save(path_save_spectrogram + 'voice_amp_db', m_amp_db_voice)\n",
        "    np.save(path_save_spectrogram + 'noise_amp_db', m_amp_db_noise)             #Not required\n",
        "    np.save(path_save_spectrogram + 'noisy_voice_amp_db', m_amp_db_noisy_voice)\n"
      ],
      "metadata": {
        "id": "HchN8NNrP3jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating folder save the audio spectograms\n",
        "!mkdir spectogram"
      ],
      "metadata": {
        "id": "m5glN5YAP6J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_dir=\"/content/noise_sound\"\n",
        "voice_dir=\"/content/clean_sound\"\n",
        "path_save_spectrogram=\"/content/spectogram/\"\n",
        "sample_rate=16000\n",
        "min_duration=1.0\n",
        "frame_length=8064\n",
        "hop_length_frame=8064\n",
        "hop_length_frame_noise=5000\n",
        "nb_samples=500\n",
        "n_fft=255\n",
        "hop_length_fft=63"
      ],
      "metadata": {
        "id": "f7uEEuhCP_Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_data(noise_dir=noise_dir,voice_dir=voice_dir,\n",
        "            path_save_spectrogram=path_save_spectrogram,\n",
        "            sample_rate=sample_rate,min_duration=min_duration,frame_length=frame_length,hop_length_frame=hop_length_frame,hop_length_frame_noise=hop_length_frame_noise,nb_samples=nb_samples,n_fft=n_fft,hop_length_fft=hop_length_fft)\n"
      ],
      "metadata": {
        "id": "rx8mbXK6P-lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_voice_amp_db = np.load('/content/spectogram/noisy_voice_amp_db.npy')\n",
        "print(np.shape(noisy_voice_amp_db))"
      ],
      "metadata": {
        "id": "xRlyhTSRQB-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend\n",
        "import tensorflow as tf\n",
        "# print(tf.__version__)\n",
        "\n",
        "#Unet network\n",
        "def unet(input_size = (128,128,1)):\n",
        "    #size filter input\n",
        "    size_filter_in = 16\n",
        "    #normal initialization of weights\n",
        "    kernel_init = 'he_normal'\n",
        "    #To apply leaky relu after the conv layer\n",
        "    activation_layer = None\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(inputs)\n",
        "    conv1 = LeakyReLU()(conv1)\n",
        "    conv1 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv1)\n",
        "    conv1 = LeakyReLU()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool1)\n",
        "    conv2 = LeakyReLU()(conv2)\n",
        "    conv2 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv2)\n",
        "    conv2 = LeakyReLU()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool2)\n",
        "    conv3 = LeakyReLU()(conv3)\n",
        "    conv3 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv3)\n",
        "    conv3 = LeakyReLU()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool3)\n",
        "    conv4 = LeakyReLU()(conv4)\n",
        "    conv4 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv4)\n",
        "    conv4 = LeakyReLU()(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(size_filter_in*16, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool4)\n",
        "    conv5 = LeakyReLU()(conv5)\n",
        "    conv5 = Conv2D(size_filter_in*16, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv5)\n",
        "    conv5 = LeakyReLU()(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(size_filter_in*8, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(drop5))\n",
        "    up6 = LeakyReLU()(up6)\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge6)\n",
        "    conv6 = LeakyReLU()(conv6)\n",
        "    conv6 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv6)\n",
        "    conv6 = LeakyReLU()(conv6)\n",
        "    up7 = Conv2D(size_filter_in*4, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(conv6))\n",
        "    up7 = LeakyReLU()(up7)\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge7)\n",
        "    conv7 = LeakyReLU()(conv7)\n",
        "    conv7 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv7)\n",
        "    conv7 = LeakyReLU()(conv7)\n",
        "    up8 = Conv2D(size_filter_in*2, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(conv7))\n",
        "    up8 = LeakyReLU()(up8)\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge8)\n",
        "    conv8 = LeakyReLU()(conv8)\n",
        "    conv8 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv8)\n",
        "    conv8 = LeakyReLU()(conv8)\n",
        "\n",
        "    up9 = Conv2D(size_filter_in, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(conv8))\n",
        "    up9 = LeakyReLU()(up9)\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge9)\n",
        "    conv9 = LeakyReLU()(conv9)\n",
        "    conv9 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv9)\n",
        "    conv9 = LeakyReLU()(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv9)\n",
        "    conv9 = LeakyReLU()(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'tanh')(conv9)\n",
        "\n",
        "    model = Model(inputs,conv10)\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = tf.keras.losses.MeanSquaredError(), metrics = ['mae'])\n",
        "    #model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "9VgPeaOMQEYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_in(matrix_spec):\n",
        "    \"global scaling apply to noisy voice spectrograms (scale between -1 and 1)\"\n",
        "    matrix_spec = (matrix_spec + 46)/50\n",
        "    return matrix_spec\n",
        "def scaled_ou(matrix_spec):\n",
        "    \"global scaling apply to noise models spectrograms (scale between -1 and 1)\"\n",
        "    matrix_spec = (matrix_spec -6 )/82\n",
        "    return matrix_spec"
      ],
      "metadata": {
        "id": "yrLiw02JQP2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_voice = np.load(\"/content/spectogram/noisy_voice_amp_db.npy\")\n",
        "voice = np.load(\"/content/spectogram/noise_amp_db.npy\")\n",
        "noise = noisy_voice-voice\n"
      ],
      "metadata": {
        "id": "36P2rfZqQTSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input\n",
        "noisy_voice = noisy_voice[:,:,:]\n",
        "noisy_voice = noisy_voice.reshape(noisy_voice.shape[0],noisy_voice.shape[1],noisy_voice.shape[2],1)\n",
        "# Output\n",
        "noise = noise[:,:,:]\n",
        "noise = noise.reshape(noise.shape[0],noise.shape[1],noise.shape[2],1)"
      ],
      "metadata": {
        "id": "XIEECPGnQXko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "def training_unet(path_save_spectrogram, weights_path, epochs, batch_size):\n",
        "    \"\"\" This function will read noisy voice and clean voice spectrograms created by data_creation mode,\n",
        "    and train a Unet model on this dataset for epochs and batch_size specified. It saves best models to disk regularly.\n",
        "    \"\"\"\n",
        "    #load noisy voice & clean voice spectrograms created by data_creation mode\n",
        "    X_in = np.load(path_save_spectrogram +'noisy_voice_amp_db'+\".npy\")\n",
        "    X_ou = np.load(path_save_spectrogram +'voice_amp_db'+\".npy\")\n",
        "    #Model of noise to predict\n",
        "    X_ou = X_in - X_ou\n",
        "\n",
        "    #Check distribution\n",
        "    print(stats.describe(X_in.reshape(-1,1)))\n",
        "    print(stats.describe(X_ou.reshape(-1,1)))\n",
        "\n",
        "    #to scale between -1 and 1\n",
        "    X_in = scaled_in(X_in)\n",
        "    X_ou = scaled_ou(X_ou)\n",
        "\n",
        "    #Check shape of spectrograms\n",
        "    print(X_in.shape)\n",
        "    print(X_ou.shape)\n",
        "    #Check new distribution\n",
        "    print(stats.describe(X_in.reshape(-1,1)))\n",
        "    print(stats.describe(X_ou.reshape(-1,1)))\n",
        "\n",
        "\n",
        "    #Reshape for training\n",
        "    X_in = X_in[:,:,:]\n",
        "    X_in = X_in.reshape(X_in.shape[0],X_in.shape[1],X_in.shape[2],1)\n",
        "    X_ou = X_ou[:,:,:]\n",
        "    X_ou = X_ou.reshape(X_ou.shape[0],X_ou.shape[1],X_ou.shape[2],1)\n",
        "    # print(X_in.shape)\n",
        "    # print(X_out.shape)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_in, X_ou, test_size=0.10, random_state=42)\n",
        "\n",
        "    generator_nn=unet()\n",
        "\n",
        "    #Save best models to disk during training\n",
        "    checkpoint = ModelCheckpoint(weights_path+'/model_unet_best.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "\n",
        "    generator_nn.summary()\n",
        "\n",
        "    #Training\n",
        "    history = generator_nn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=True, callbacks=[checkpoint], verbose=1, validation_data=(X_test, y_test))\n",
        "    model_in_json = generator_nn.to_json()\n",
        "\n",
        "    #Saving Model\n",
        "    with open(weights_path+'model_unet.json','w') as json_file:\n",
        "      json_file.write(model_in_json)\n",
        "\n",
        "    #Plot training and validation loss (log scale)\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    plt.plot(epochs, loss, label='Training loss')\n",
        "    plt.plot(epochs, val_loss, label='Validation loss')\n",
        "    plt.yscale('log')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "93R5wlw-QYl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir weights"
      ],
      "metadata": {
        "id": "BWubMKi-QhfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_unet(path_save_spectrogram, './weights', epochs=  20,batch_size=10)"
      ],
      "metadata": {
        "id": "XW0nL7gHQhYL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}